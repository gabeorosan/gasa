{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m headers \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mAuthorization\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mBearer \u001b[39m\u001b[39m{\u001b[39;00maccess_token\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m}\n\u001b[1;32m      9\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(search_url, params\u001b[39m=\u001b[39mparams, headers\u001b[39m=\u001b[39mheaders)\n\u001b[0;32m---> 10\u001b[0m song_info \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39;49mjson()[\u001b[39m'\u001b[39;49m\u001b[39mresponse\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39mhits\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m0\u001b[39;49m][\u001b[39m'\u001b[39m\u001b[39mresult\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from tokens import token\n",
    "\n",
    "access_token = token\n",
    "search_url = 'https://api.genius.com/search'\n",
    "params = {'q': 'Hakujitsu English'}\n",
    "headers = {'Authorization': f'Bearer {access_token}'}\n",
    "\n",
    "response = requests.get(search_url, params=params, headers=headers)\n",
    "song_info = response.json()['response']['hits'][0]['result']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'annotation_count': 1,\n",
       " 'api_path': '/songs/4427549',\n",
       " 'artist_names': 'King Gnu',\n",
       " 'full_title': '白日 (Hakujitsu) by\\xa0King\\xa0Gnu',\n",
       " 'header_image_thumbnail_url': 'https://images.genius.com/1fca00f8262281c4af1f85ef662bb5e3.300x300x1.jpg',\n",
       " 'header_image_url': 'https://images.genius.com/1fca00f8262281c4af1f85ef662bb5e3.1000x1000x1.jpg',\n",
       " 'id': 4427549,\n",
       " 'lyrics_owner_id': 6679555,\n",
       " 'lyrics_state': 'complete',\n",
       " 'path': '/King-gnu-hakujitsu-lyrics',\n",
       " 'pyongs_count': 2,\n",
       " 'relationships_index_url': 'https://genius.com/King-gnu-hakujitsu-sample',\n",
       " 'release_date_components': {'year': 2019, 'month': 2, 'day': 22},\n",
       " 'release_date_for_display': 'February 22, 2019',\n",
       " 'release_date_with_abbreviated_month_for_display': 'Feb. 22, 2019',\n",
       " 'song_art_image_thumbnail_url': 'https://images.genius.com/1fca00f8262281c4af1f85ef662bb5e3.300x300x1.jpg',\n",
       " 'song_art_image_url': 'https://images.genius.com/1fca00f8262281c4af1f85ef662bb5e3.1000x1000x1.jpg',\n",
       " 'stats': {'unreviewed_annotations': 1, 'hot': False, 'pageviews': 10016},\n",
       " 'title': '白日 (Hakujitsu)',\n",
       " 'title_with_featured': '白日 (Hakujitsu)',\n",
       " 'url': 'https://genius.com/King-gnu-hakujitsu-lyrics',\n",
       " 'featured_artists': [],\n",
       " 'primary_artist': {'api_path': '/artists/1564830',\n",
       "  'header_image_url': 'https://images.genius.com/77a4394df755825a55b83b734d578111.1000x667x1.jpg',\n",
       "  'id': 1564830,\n",
       "  'image_url': 'https://images.genius.com/61116f0558ae73c12fbfed3f187e97c2.788x788x1.png',\n",
       "  'is_meme_verified': False,\n",
       "  'is_verified': False,\n",
       "  'name': 'King Gnu',\n",
       "  'url': 'https://genius.com/artists/King-gnu'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "song_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NoneType' object has no attribute 'cadam32bit_grad_fp32'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (512) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Like a crazy carbonic acid.\n"
     ]
    }
   ],
   "source": [
    "# Load the tokenizer and model for the specific Japanese-to-English translation\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-ja-en\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-ja-en\")\n",
    "\n",
    "# Japanese text you want to translate\n",
    "text = \"気の抜けた炭酸みたいに\"\n",
    "\n",
    "# Tokenize the text and generate translation\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs)\n",
    "\n",
    "# Decode the translation and print\n",
    "translation = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(translation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b293f2d5ee4380b7883b434dc1dc00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "201f581062ec4bfc90f1e11f0e23d447",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.39k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d5f62779a3d49f4aa3f5b7f0d8106b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/source.spm:   0%|          | 0.00/842k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad9dd465c21e4694927a201cae3827c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/target.spm:   0%|          | 0.00/813k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e1549a577774e0895ac862e34204b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.72M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5725742c381240e88d70d9da269affa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/312M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563aa657b3be4eb5b87aeced74d50969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You who stopped at the place you used to love.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-ko-en\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-jp-en\")\n",
    "text = \"幽霊 に なっ た 僕 は 、 明日 遠く の 君 を 見 に 行く ん だ その後 は どう しよ う\"\n",
    "\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model.generate(**inputs)\n",
    "\n",
    "translation = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lyrics.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "with open('script.txt', 'w') as file:\n",
    "    for index, line in enumerate(lines):\n",
    "        formatted_line = f\"{index+1:05}\\t{line}\"\n",
    "        file.write(formatted_line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoConfig, AutoModelForCTC, AutoProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model_handling'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoTokenizer, AutoFeatureExtractor\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodel_handling\u001b[39;00m \u001b[39mimport\u001b[39;00m Wav2Vec2ForCTC\n\u001b[1;32m      4\u001b[0m model_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mnguyenvulebinh/lyric-alignment\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      5\u001b[0m model \u001b[39m=\u001b[39m Wav2Vec2ForCTC\u001b[39m.\u001b[39mfrom_pretrained(model_path)\u001b[39m.\u001b[39meval()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'model_handling'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoFeatureExtractor\n",
    "from model_handling import Wav2Vec2ForCTC\n",
    "\n",
    "model_path = 'nguyenvulebinh/lyric-alignment'\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_path).eval()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_path)\n",
    "vocab = [tokenizer.convert_ids_to_tokens(i) for i in range(len(tokenizer.get_vocab()))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from predict import handle_sample\n",
    "import torchaudio\n",
    "import json\n",
    "\n",
    "# wav_path: path to audio file. Need to be 16k and single channel. \n",
    "# path_lyric: path to lyric data in json format, which includes list of segment and words\n",
    "wav, _ = torchaudio.load(wav_path)\n",
    "with open(path_lyric, 'r', encoding='utf-8') as file:\n",
    "    lyric_data = json.load(file)\n",
    "lyric_alignment = handle_sample(wav, lyric_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
